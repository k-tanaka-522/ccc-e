#!/bin/bash
# SRE Agent - é‹ç”¨ãƒ»ç›£è¦–ãƒ»è‡ªå‹•åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

# è¨­å®š
AGENT_NAME="SRE Agent"
AGENT_VERSION="1.0.0"
REQUIREMENTS_DIR="../requirements"
ARCHITECTURE_DIR="../architecture"
AWS_DIR="../aws"
OUTPUT_DIR="../ops"
TEMPLATES_DIR="templates/sre"

# ãƒ­ã‚°é–¢æ•°
log_info() {
    echo -e "\033[1;34m[INFO]\033[0m $1"
}

log_success() {
    echo -e "\033[1;32m[SUCCESS]\033[0m $1"
}

log_error() {
    echo -e "\033[1;31m[ERROR]\033[0m $1"
}

log_warn() {
    echo -e "\033[1;33m[WARN]\033[0m $1"
}

# ä½¿ç”¨æ–¹æ³•ã®è¡¨ç¤º
show_usage() {
    cat << EOF
ğŸ”§ SRE Agent v${AGENT_VERSION}
=============================

ä½¿ç”¨æ–¹æ³•:
  $0 [ã‚ªãƒ—ã‚·ãƒ§ãƒ³]

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  --monitoring       ç›£è¦–è¨­å®šã‚’ç”Ÿæˆ
  --alerting         ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã‚’ç”Ÿæˆ
  --logging          ãƒ­ã‚°è¨­å®šã‚’ç”Ÿæˆ
  --backup           ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã‚’ç”Ÿæˆ
  --disaster         ç½å®³å¾©æ—§è¨ˆç”»ã‚’ç”Ÿæˆ
  --runbooks         ãƒ©ãƒ³ãƒ–ãƒƒã‚¯ã‚’ç”Ÿæˆ
  --automation       é‹ç”¨è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆ
  --security         ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã‚’ç”Ÿæˆ
  --performance      ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚’ç”Ÿæˆ
  --cost             ã‚³ã‚¹ãƒˆç›£è¦–ã‚’ç”Ÿæˆ
  --slo              SLO/SLIè¨­å®šã‚’ç”Ÿæˆ
  --all              å…¨ã¦ã®é‹ç”¨è¨­å®šã‚’ç”Ÿæˆ
  --help             ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º

ä¾‹:
  $0 --monitoring --level standard
  $0 --alerting --slo 99.9
  $0 --runbooks
  $0 --all

EOF
}

# åˆæœŸåŒ–
init_sre() {
    log_info "SREç’°å¢ƒã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™..."
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    mkdir -p "$OUTPUT_DIR" logs tmp
    mkdir -p "$OUTPUT_DIR"/{monitoring,alerting,logging,backup,runbooks,automation,security}
    mkdir -p "$OUTPUT_DIR/automation"/{scripts,terraform,ansible}
    
    log_success "SREç’°å¢ƒã®åˆæœŸåŒ–å®Œäº†"
}

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã®èª­ã¿è¾¼ã¿
load_project_info() {
    log_info "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."
    
    # è¦ä»¶å®šç¾©ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
    if [ -f "$REQUIREMENTS_DIR/requirements.md" ]; then
        SLO=$(grep -o "å¯ç”¨æ€§ç›®æ¨™.*[0-9]\+\.[0-9]\+%" "$REQUIREMENTS_DIR/requirements.md" | grep -o "[0-9]\+\.[0-9]\+%" | head -1)
        CONCURRENT_USERS=$(grep -o "æƒ³å®šãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°.*[0-9]\+" "$REQUIREMENTS_DIR/requirements.md" | grep -o "[0-9]\+" | head -1)
        RESPONSE_TIME=$(grep -o "ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ .*[0-9]\+" "$REQUIREMENTS_DIR/requirements.md" | grep -o "[0-9]\+" | head -1)
        COST_LIMIT=$(grep -o "ã‚³ã‚¹ãƒˆä¸Šé™.*[0-9]\+" "$REQUIREMENTS_DIR/requirements.md" | grep -o "[0-9]\+" | head -1)
    fi
    
    # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
    if [ -f "$ARCHITECTURE_DIR/design.md" ]; then
        if grep -qi "serverless\|lambda" "$ARCHITECTURE_DIR/design.md"; then
            DEPLOYMENT_TYPE="serverless"
        elif grep -qi "container\|ecs\|docker" "$ARCHITECTURE_DIR/design.md"; then
            DEPLOYMENT_TYPE="container"
        else
            DEPLOYMENT_TYPE="traditional"
        fi
    fi
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
    SLO=${SLO:-"99.9%"}
    CONCURRENT_USERS=${CONCURRENT_USERS:-1000}
    RESPONSE_TIME=${RESPONSE_TIME:-2}
    COST_LIMIT=${COST_LIMIT:-500}
    DEPLOYMENT_TYPE=${DEPLOYMENT_TYPE:-"traditional"}
    
    # SLOã«åŸºã¥ãç›£è¦–ãƒ¬ãƒ™ãƒ«æ±ºå®š
    case "$SLO" in
        "99.0%") MONITORING_LEVEL="basic" ;;
        "99.9%") MONITORING_LEVEL="standard" ;;
        "99.95%"|"99.99%") MONITORING_LEVEL="advanced" ;;
        *) MONITORING_LEVEL="standard" ;;
    esac
    
    log_success "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±èª­ã¿è¾¼ã¿å®Œäº†"
    log_info "SLO: $SLO, ç›£è¦–ãƒ¬ãƒ™ãƒ«: $MONITORING_LEVEL, ãƒ‡ãƒ—ãƒ­ã‚¤ç¨®åˆ¥: $DEPLOYMENT_TYPE"
}

# ç›£è¦–è¨­å®šç”Ÿæˆ
generate_monitoring() {
    local level="$1"
    level=${level:-$MONITORING_LEVEL}
    
    log_info "ç›£è¦–è¨­å®šã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™: $level"
    
    load_project_info
    
    # CloudWatchè¨­å®š
    generate_cloudwatch_config "$level"
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    generate_custom_metrics "$level"
    
    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    generate_dashboard_config "$level"
    
    # ç›£è¦–è¨ˆç”»æ›¸
    generate_monitoring_plan "$level"
    
    log_success "ç›£è¦–è¨­å®šç”Ÿæˆå®Œäº†"
}

# CloudWatchè¨­å®šç”Ÿæˆ
generate_cloudwatch_config() {
    local level="$1"
    
    cat > "$OUTPUT_DIR/monitoring/cloudwatch.yaml" << EOF
# CloudWatch ç›£è¦–è¨­å®š
AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudWatch monitoring configuration'

Parameters:
  Environment:
    Type: String
    Default: prod
  AlertEmail:
    Type: String
    Description: Email for alerts

Resources:
  # SNS Topic for alerts
  AlertTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub \${Environment}-alerts
      Subscription:
        - Protocol: email
          Endpoint: !Ref AlertEmail

  # CloudWatch Dashboard
  MonitoringDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub \${Environment}-monitoring
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "properties": {
                "metrics": [
                  ["AWS/ApplicationELB", "RequestCount"],
                  ["AWS/ApplicationELB", "TargetResponseTime"],
                  ["AWS/ApplicationELB", "HTTPCode_Target_4XX_Count"],
                  ["AWS/ApplicationELB", "HTTPCode_Target_5XX_Count"]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "us-east-1",
                "title": "Load Balancer Metrics"
              }
            },
$(generate_additional_widgets "$level")
          ]
        }

  # Basic Alarms
$(generate_basic_alarms "$level")

$(if [ "$level" != "basic" ]; then
    echo "  # Advanced Alarms"
    generate_advanced_alarms "$level"
fi)

Outputs:
  DashboardURL:
    Description: CloudWatch Dashboard URL
    Value: !Sub "https://console.aws.amazon.com/cloudwatch/home?region=\${AWS::Region}#dashboards:name=\${MonitoringDashboard}"
EOF
}

# åŸºæœ¬ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ
generate_basic_alarms() {
    local level="$1"
    
    cat << 'EOF'
  # High CPU Alarm
  HighCPUAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${Environment}-high-cpu
      AlarmDescription: High CPU utilization detected
      MetricName: CPUUtilization
      Namespace: AWS/EC2
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 80
      ComparisonOperator: GreaterThanThreshold
      AlarmActions:
        - !Ref AlertTopic

  # High Memory Alarm
  HighMemoryAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${Environment}-high-memory
      AlarmDescription: High memory utilization detected
      MetricName: MemoryUtilization
      Namespace: CWAgent
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 85
      ComparisonOperator: GreaterThanThreshold
      AlarmActions:
        - !Ref AlertTopic

  # HTTP 5xx Errors
  HTTP5xxAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${Environment}-http-5xx-errors
      AlarmDescription: High rate of 5xx errors
      MetricName: HTTPCode_Target_5XX_Count
      Namespace: AWS/ApplicationELB
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 2
      Threshold: 10
      ComparisonOperator: GreaterThanThreshold
      AlarmActions:
        - !Ref AlertTopic
EOF
}

# ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šç”Ÿæˆ
generate_alerting() {
    local slo="$1"
    slo=${slo:-$SLO}
    
    log_info "ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™: SLO $slo"
    
    load_project_info
    
    # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«
    generate_alert_rules "$slo"
    
    # PagerDutyè¨­å®š
    generate_pagerduty_config
    
    # Slackè¨­å®š
    generate_slack_config
    
    # ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
    generate_escalation_policy "$slo"
    
    log_success "ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šç”Ÿæˆå®Œäº†"
}

# ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ç”Ÿæˆ
generate_alert_rules() {
    local slo="$1"
    
    # SLOã«åŸºã¥ãé–¾å€¤è¨ˆç®—
    local error_budget
    case "$slo" in
        "99.0%") error_budget="1.0" ;;
        "99.9%") error_budget="0.1" ;;
        "99.95%") error_budget="0.05" ;;
        "99.99%") error_budget="0.01" ;;
        *) error_budget="0.1" ;;
    esac
    
    cat > "$OUTPUT_DIR/alerting/alert-rules.yaml" << EOF
# ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«è¨­å®š
groups:
  - name: slo-alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > $error_budget
        for: 5m
        labels:
          severity: critical
          slo: availability
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ \$value | humanizePercentage }} which exceeds SLO of $slo"

      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > $RESPONSE_TIME
        for: 5m
        labels:
          severity: warning
          slo: latency
        annotations:
          summary: "High latency detected"
          description: "95th percentile latency is {{ \$value }}s which exceeds target of ${RESPONSE_TIME}s"

      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          slo: availability
        annotations:
          summary: "Service is down"
          description: "{{ \$labels.instance }} has been down for more than 1 minute"

  - name: infrastructure-alerts
    rules:
      - alert: HighCPU
        expr: cpu_usage_percent > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ \$value }}% on {{ \$labels.instance }}"

      - alert: HighMemory
        expr: memory_usage_percent > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ \$value }}% on {{ \$labels.instance }}"

      - alert: DiskSpaceLow
        expr: disk_free_percent < 15
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space"
          description: "Disk space is {{ \$value }}% free on {{ \$labels.instance }}"

  - name: database-alerts
    rules:
      - alert: DatabaseConnectionsHigh
        expr: database_connections_active / database_connections_max > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database connection usage is {{ \$value | humanizePercentage }}"

      - alert: DatabaseSlowQueries
        expr: rate(database_slow_queries_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow database queries detected"
          description: "Slow query rate is {{ \$value }} per second"

  - name: cost-alerts
    rules:
      - alert: HighCost
        expr: aws_billing_estimated_charges > $COST_LIMIT
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "High AWS costs"
          description: "AWS costs are \${{ \$value }} which exceeds budget of \$$COST_LIMIT"
EOF
}

# ãƒ­ã‚°è¨­å®šç”Ÿæˆ
generate_logging() {
    log_info "ãƒ­ã‚°è¨­å®šã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."
    
    load_project_info
    
    # ãƒ­ã‚°åé›†è¨­å®š
    generate_log_collection_config
    
    # ãƒ­ã‚°ãƒ‘ãƒ¼ã‚¹è¨­å®š
    generate_log_parsing_config
    
    # ãƒ­ã‚°ä¿æŒãƒãƒªã‚·ãƒ¼
    generate_log_retention_policy
    
    # ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–è¨­å®š
    generate_log_archive_config
    
    log_success "ãƒ­ã‚°è¨­å®šç”Ÿæˆå®Œäº†"
}

# ãƒ­ã‚°åé›†è¨­å®šç”Ÿæˆ
generate_log_collection_config() {
    case "$DEPLOYMENT_TYPE" in
        "container")
            generate_container_logging
            ;;
        "serverless")
            generate_serverless_logging
            ;;
        *)
            generate_traditional_logging
            ;;
    esac
}

# ã‚³ãƒ³ãƒ†ãƒŠãƒ­ã‚®ãƒ³ã‚°è¨­å®š
generate_container_logging() {
    cat > "$OUTPUT_DIR/logging/fluentd.conf" << 'EOF'
# Fluentd configuration for container logging

<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<source>
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  format json
  read_from_head true
</source>

# Parse application logs
<filter kubernetes.**>
  @type kubernetes_metadata
</filter>

<filter kubernetes.**>
  @type parser
  key_name log
  reserve_data true
  remove_key_name_field true
  <parse>
    @type multi_format
    <pattern>
      format json
    </pattern>
    <pattern>
      format none
    </pattern>
  </parse>
</filter>

# Add severity based on log level
<filter kubernetes.**>
  @type record_transformer
  <record>
    severity ${record.dig("level") == "error" ? "ERROR" : record.dig("level") == "warn" ? "WARNING" : "INFO"}
  </record>
</filter>

# Output to CloudWatch Logs
<match kubernetes.**>
  @type cloudwatch_logs
  log_group_name /aws/containerinsights/#{ENV['CLUSTER_NAME']}/application
  log_stream_name_key stream_name
  auto_create_stream true
  remove_log_stream_name_key true
  <buffer>
    flush_interval 5s
    chunk_limit_size 2m
    queued_chunks_limit_size 32
  </buffer>
</match>

# Output errors to separate stream
<match **>
  @type copy
  <store>
    @type cloudwatch_logs
    log_group_name /aws/application/logs
    log_stream_name general
    auto_create_stream true
  </store>
  <store>
    @type stdout
  </store>
</match>
EOF
}

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ç”Ÿæˆ
generate_backup() {
    log_info "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."
    
    load_project_info
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨ˆç”»
    generate_backup_plan
    
    # è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    generate_backup_scripts
    
    # å¾©å…ƒæ‰‹é †
    generate_restore_procedures
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆè¨ˆç”»
    generate_backup_testing_plan
    
    log_success "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ç”Ÿæˆå®Œäº†"
}

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨ˆç”»ç”Ÿæˆ
generate_backup_plan() {
    cat > "$OUTPUT_DIR/backup/backup-plan.md" << EOF
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨ˆç”»

## æ¦‚è¦
- **SLO**: $SLO
- **RTO (Recovery Time Objective)**: $(calculate_rto "$SLO")
- **RPO (Recovery Point Objective)**: $(calculate_rpo "$SLO")

## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- **é »åº¦**: æ—¥æ¬¡ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— + ç¶™ç¶šçš„ãƒ­ã‚°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- **ä¿æŒæœŸé–“**: 30æ—¥é–“
- **æš—å·åŒ–**: AES-256
- **ãƒ†ã‚¹ãƒˆé »åº¦**: é€±æ¬¡

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
- **é »åº¦**: æ—¥æ¬¡
- **ä¿æŒæœŸé–“**: 7æ—¥é–“
- **å¯¾è±¡**: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«

### è¨­å®šãƒ»Infrastructure as Code
- **é »åº¦**: å¤‰æ›´æ™‚ï¼ˆGitç®¡ç†ï¼‰
- **ä¿æŒæœŸé–“**: ç„¡æœŸé™
- **å¯¾è±¡**: CloudFormationã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

| å¯¾è±¡ | é »åº¦ | æ™‚åˆ» | ä¿æŒæœŸé–“ | æš—å·åŒ– |
|------|------|------|----------|--------|
| RDS | æ—¥æ¬¡ | 03:00 UTC | 30æ—¥ | âœ… |
| S3 | ç¶™ç¶šçš„ | - | 30æ—¥ | âœ… |
| EBS | æ—¥æ¬¡ | 04:00 UTC | 7æ—¥ | âœ… |
| Config | å¤‰æ›´æ™‚ | - | æ°¸ç¶š | âœ… |

## ç½å®³å¾©æ—§ã‚·ãƒŠãƒªã‚ª

### ã‚·ãƒŠãƒªã‚ª1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹éšœå®³
- **RTO**: $(calculate_rto "$SLO")
- **RPO**: 15åˆ†
- **æ‰‹é †**: RDSè‡ªå‹•ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼

### ã‚·ãƒŠãƒªã‚ª2: AZéšœå®³
- **RTO**: $(calculate_rto "$SLO")  
- **RPO**: 15åˆ†
- **æ‰‹é †**: Multi-AZè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ

### ã‚·ãƒŠãƒªã‚ª3: ãƒªãƒ¼ã‚¸ãƒ§ãƒ³éšœå®³
- **RTO**: 4æ™‚é–“
- **RPO**: 1æ™‚é–“
- **æ‰‹é †**: æ‰‹å‹•ã‚¯ãƒ­ã‚¹ãƒªãƒ¼ã‚¸ãƒ§ãƒ³å¾©å…ƒ

## å¾©å…ƒæ‰‹é †

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©å…ƒ
\`\`\`bash
# Point-in-time recovery
aws rds restore-db-instance-to-point-in-time \\
  --target-db-instance-identifier mydb-restored \\
  --source-db-instance-identifier mydb \\
  --restore-time 2023-01-01T12:00:00Z

# ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ã®å¾©å…ƒ
aws rds restore-db-instance-from-db-snapshot \\
  --db-instance-identifier mydb-restored \\
  --db-snapshot-identifier mydb-snapshot-20230101
\`\`\`

### ãƒ•ã‚¡ã‚¤ãƒ«å¾©å…ƒ
\`\`\`bash
# S3ã‹ã‚‰ã®å¾©å…ƒ
aws s3 sync s3://backup-bucket/latest/ ./restore/

# EBSã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ã®å¾©å…ƒ
aws ec2 create-volume --snapshot-id snap-12345678 \\
  --availability-zone us-east-1a
\`\`\`

## ãƒ†ã‚¹ãƒˆè¨ˆç”»

### é€±æ¬¡ãƒ†ã‚¹ãƒˆ
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œæ•´æ€§ãƒã‚§ãƒƒã‚¯
- å°è¦æ¨¡å¾©å…ƒãƒ†ã‚¹ãƒˆ

### æœˆæ¬¡ãƒ†ã‚¹ãƒˆ
- ãƒ•ãƒ«å¾©å…ƒãƒ†ã‚¹ãƒˆï¼ˆdevç’°å¢ƒï¼‰
- å¾©æ—§æ™‚é–“æ¸¬å®š

### å››åŠæœŸãƒ†ã‚¹ãƒˆ
- ç½å®³å¾©æ—§è¨“ç·´
- ã‚¯ãƒ­ã‚¹ãƒªãƒ¼ã‚¸ãƒ§ãƒ³å¾©å…ƒ

## ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç›£è¦–
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸ/å¤±æ•—
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚ºç•°å¸¸
- å¾©å…ƒãƒ†ã‚¹ãƒˆçµæœ

### ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—æ™‚: å³åº§ã«ã‚¢ãƒ©ãƒ¼ãƒˆ
- RPO/RTOè¶…éæ™‚: ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- ãƒ†ã‚¹ãƒˆå¤±æ•—æ™‚: ç¿Œå–¶æ¥­æ—¥å¯¾å¿œ
EOF
}

# RTOè¨ˆç®—
calculate_rto() {
    local slo="$1"
    case "$slo" in
        "99.0%") echo "4æ™‚é–“" ;;
        "99.9%") echo "1æ™‚é–“" ;;
        "99.95%") echo "30åˆ†" ;;
        "99.99%") echo "15åˆ†" ;;
        *) echo "1æ™‚é–“" ;;
    esac
}

# RPOè¨ˆç®—
calculate_rpo() {
    local slo="$1"
    case "$slo" in
        "99.0%") echo "1æ™‚é–“" ;;
        "99.9%") echo "15åˆ†" ;;
        "99.95%") echo "5åˆ†" ;;
        "99.99%") echo "1åˆ†" ;;
        *) echo "15åˆ†" ;;
    esac
}

# ãƒ©ãƒ³ãƒ–ãƒƒã‚¯ç”Ÿæˆ
generate_runbooks() {
    log_info "ãƒ©ãƒ³ãƒ–ãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."
    
    load_project_info
    
    # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œãƒ©ãƒ³ãƒ–ãƒƒã‚¯
    generate_incident_runbooks
    
    # å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ‰‹é †
    generate_maintenance_runbooks
    
    # ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰
    generate_troubleshooting_guide
    
    log_success "ãƒ©ãƒ³ãƒ–ãƒƒã‚¯ç”Ÿæˆå®Œäº†"
}

# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œãƒ©ãƒ³ãƒ–ãƒƒã‚¯
generate_incident_runbooks() {
    cat > "$OUTPUT_DIR/runbooks/incident-response.md" << 'EOF'
# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œãƒ©ãƒ³ãƒ–ãƒƒã‚¯

## æ¦‚è¦
ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç™ºç”Ÿæ™‚ã®å¯¾å¿œæ‰‹é †ã‚’å®šç¾©ã™ã‚‹ã€‚

## ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆåˆ†é¡

### Severity 1 (Critical)
- **å®šç¾©**: ã‚µãƒ¼ãƒ“ã‚¹å®Œå…¨åœæ­¢ã€é‡å¤§ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³
- **å¯¾å¿œæ™‚é–“**: 15åˆ†ä»¥å†…ã«åˆæœŸå¯¾å¿œ
- **ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: å³åº§ã«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã«å ±å‘Š

### Severity 2 (High)
- **å®šç¾©**: æ©Ÿèƒ½ã®ä¸€éƒ¨åœæ­¢ã€é‡å¤§ãªæ€§èƒ½åŠ£åŒ–
- **å¯¾å¿œæ™‚é–“**: 1æ™‚é–“ä»¥å†…ã«åˆæœŸå¯¾å¿œ
- **ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: 2æ™‚é–“ä»¥å†…ã«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã«å ±å‘Š

### Severity 3 (Medium)
- **å®šç¾©**: è»½å¾®ãªæ©Ÿèƒ½ä¸å…·åˆã€è»½å¾®ãªæ€§èƒ½å•é¡Œ
- **å¯¾å¿œæ™‚é–“**: 4æ™‚é–“ä»¥å†…ã«åˆæœŸå¯¾å¿œ
- **ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ç¿Œå–¶æ¥­æ—¥ã«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã«å ±å‘Š

## å¯¾å¿œãƒ•ãƒ­ãƒ¼

### 1. ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ¤œçŸ¥
```mermaid
graph TD
    A[ã‚¢ãƒ©ãƒ¼ãƒˆå—ä¿¡] --> B[é‡è¦åº¦åˆ¤å®š]
    B --> C{Severity 1?}
    C -->|Yes| D[å³åº§ã«ã‚ªãƒ³ã‚³ãƒ¼ãƒ«]
    C -->|No| E[é€šå¸¸å¯¾å¿œé–‹å§‹]
    D --> F[æˆ¦æ™‚æ…‹å‹¢é–‹å§‹]
    E --> G[èª¿æŸ»é–‹å§‹]
    F --> G
```

### 2. åˆæœŸå¯¾å¿œæ‰‹é †

#### Step 1: çŠ¶æ³ç¢ºèª (5åˆ†)
```bash
# ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
curl -I https://api.example.com/health

# ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
aws cloudwatch get-metric-statistics \
  --namespace AWS/ApplicationELB \
  --metric-name TargetResponseTime \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Average

# ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç¢ºèª
aws logs filter-log-events \
  --log-group-name /aws/lambda/api \
  --start-time $(date -d '1 hour ago' +%s)000 \
  --filter-pattern 'ERROR'
```

#### Step 2: å½±éŸ¿ç¯„å›²ç‰¹å®š (10åˆ†)
- å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
- å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿèƒ½
- åœ°ç†çš„ãªå½±éŸ¿ç¯„å›²
- ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®å½±éŸ¿

#### Step 3: ä¸€æ™‚çš„å›é¿ç­– (15åˆ†)
```bash
# ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ¶é™
aws elbv2 modify-target-group \
  --target-group-arn arn:aws:elasticloadbalancing:... \
  --health-check-interval-seconds 10

# ç·Šæ€¥ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒšãƒ¼ã‚¸è¡¨ç¤º
aws s3 cp maintenance.html s3://cdn-bucket/index.html

# Auto Scalingèª¿æ•´
aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name web-asg \
  --desired-capacity 10
```

### 3. æ ¹æœ¬åŸå› åˆ†æ

#### ãƒ‡ãƒ¼ã‚¿åé›†
- ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°
- å¤–éƒ¨ä¾å­˜é–¢ä¿‚ã®çŠ¶æ…‹
- æœ€è¿‘ã®ãƒ‡ãƒ—ãƒ­ã‚¤å±¥æ­´

#### åˆ†ææ‰‹æ³•
1. **Timelineåˆ†æ**: å•é¡Œç™ºç”Ÿå‰å¾Œã®å¤‰æ›´ç‚¹
2. **5 Whys**: æ ¹æœ¬åŸå› ã®æ·±æ˜ã‚Š
3. **Fishbone diagram**: è¦å› ã®ä½“ç³»åŒ–

### 4. å¾©æ—§æ‰‹é †

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£
```bash
# æ¥ç¶šæ•°ç¢ºèª
aws rds describe-db-instances \
  --db-instance-identifier production-db

# ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªç¢ºèª
mysql -h $DB_HOST -u $DB_USER -p$DB_PASS \
  -e "SHOW PROCESSLIST;"

# ç·Šæ€¥æ™‚ã®Read Replicaæ˜‡æ ¼
aws rds promote-read-replica \
  --db-instance-identifier production-db-replica
```

#### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–¢é€£
```bash
# ã‚³ãƒ³ãƒ†ãƒŠå†èµ·å‹•
aws ecs update-service \
  --cluster production \
  --service web-service \
  --force-new-deployment

# å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¸ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
kubectl rollout undo deployment/web-app

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
redis-cli FLUSHALL
```

### 5. äº‹å¾Œå¯¾å¿œ

#### ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
- **æ¦‚è¦**: ä½•ãŒèµ·ããŸã‹
- **å½±éŸ¿**: èª°ã«ã€ã©ã®ç¨‹åº¦å½±éŸ¿ã—ãŸã‹
- **æ ¹æœ¬åŸå› **: ãªãœèµ·ããŸã‹
- **å¯¾å¿œ**: ä½•ã‚’ã—ãŸã‹
- **æ”¹å–„ç­–**: å†ç™ºé˜²æ­¢ã®ãŸã‚ã®æ–½ç­–

#### ãƒã‚¹ãƒˆãƒ¢ãƒ¼ãƒ†ãƒ å®Ÿæ–½
- äº‹å®Ÿã®æ•´ç†ï¼ˆblame-freeï¼‰
- ãƒ—ãƒ­ã‚»ã‚¹ã®æ”¹å–„ç‚¹
- æŠ€è¡“çš„ãªæ”¹å–„ç‚¹
- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã®è¨­å®š

## é€£çµ¡å…ˆ

### ã‚ªãƒ³ã‚³ãƒ¼ãƒ«
- **Primary**: +81-90-1234-5678
- **Secondary**: +81-90-1234-5679
- **Manager**: +81-90-1234-5680

### ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **Level 1**: ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ‰
- **Level 2**: ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
- **Level 3**: CTO

## ãƒ„ãƒ¼ãƒ«ãƒ»ãƒªã‚½ãƒ¼ã‚¹

### ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- CloudWatch Dashboard: https://console.aws.amazon.com/cloudwatch/
- Grafana: https://grafana.company.com/
- PagerDuty: https://company.pagerduty.com/

### ãƒ­ã‚°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- CloudWatch Logs: https://console.aws.amazon.com/cloudwatch/
- Elasticsearch: https://elasticsearch.company.com/
- Jaeger Tracing: https://jaeger.company.com/

### ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- Slack: #incident-response
- Zoom: https://zoom.us/j/incident-room
- Status Page: https://status.company.com/
EOF
}

# é‹ç”¨è‡ªå‹•åŒ–ç”Ÿæˆ
generate_automation() {
    log_info "é‹ç”¨è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."
    
    load_project_info
    
    # ãƒ‡ãƒ—ãƒ­ã‚¤è‡ªå‹•åŒ–
    generate_deployment_automation
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è‡ªå‹•åŒ–
    generate_scaling_automation
    
    # å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è‡ªå‹•åŒ–
    generate_maintenance_automation
    
    # éšœå®³å¾©æ—§è‡ªå‹•åŒ–
    generate_recovery_automation
    
    log_success "é‹ç”¨è‡ªå‹•åŒ–ç”Ÿæˆå®Œäº†"
}

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è‡ªå‹•åŒ–
generate_scaling_automation() {
    cat > "$OUTPUT_DIR/automation/scripts/auto-scaling.sh" << 'EOF'
#!/bin/bash
# Auto Scaling è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

# è¨­å®š
ASG_NAME="web-app-asg"
MIN_SIZE=2
MAX_SIZE=20
TARGET_CPU=70
SCALE_UP_COOLDOWN=300
SCALE_DOWN_COOLDOWN=300

# ãƒ­ã‚°é–¢æ•°
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
get_cpu_utilization() {
    aws cloudwatch get-metric-statistics \
        --namespace AWS/EC2 \
        --metric-name CPUUtilization \
        --dimensions Name=AutoScalingGroupName,Value=$ASG_NAME \
        --start-time $(date -u -d '10 minutes ago' +%Y-%m-%dT%H:%M:%S) \
        --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
        --period 300 \
        --statistics Average \
        --query 'Datapoints[0].Average' \
        --output text
}

# ç¾åœ¨ã®ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£å–å¾—
get_current_capacity() {
    aws autoscaling describe-auto-scaling-groups \
        --auto-scaling-group-names $ASG_NAME \
        --query 'AutoScalingGroups[0].DesiredCapacity' \
        --output text
}

# ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—
scale_up() {
    local current_capacity=$1
    local new_capacity=$((current_capacity + 2))
    
    if [ $new_capacity -gt $MAX_SIZE ]; then
        new_capacity=$MAX_SIZE
    fi
    
    log "Scaling up from $current_capacity to $new_capacity"
    
    aws autoscaling set-desired-capacity \
        --auto-scaling-group-name $ASG_NAME \
        --desired-capacity $new_capacity \
        --honor-cooldown
}

# ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
scale_down() {
    local current_capacity=$1
    local new_capacity=$((current_capacity - 1))
    
    if [ $new_capacity -lt $MIN_SIZE ]; then
        new_capacity=$MIN_SIZE
    fi
    
    log "Scaling down from $current_capacity to $new_capacity"
    
    aws autoscaling set-desired-capacity \
        --auto-scaling-group-name $ASG_NAME \
        --desired-capacity $new_capacity \
        --honor-cooldown
}

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
main() {
    log "Starting auto-scaling check"
    
    local cpu_util=$(get_cpu_utilization)
    local current_capacity=$(get_current_capacity)
    
    log "Current CPU utilization: ${cpu_util}%"
    log "Current capacity: $current_capacity"
    
    if (( $(echo "$cpu_util > 80" | bc -l) )); then
        log "High CPU detected, scaling up"
        scale_up $current_capacity
    elif (( $(echo "$cpu_util < 40" | bc -l) )); then
        log "Low CPU detected, scaling down"
        scale_down $current_capacity
    else
        log "CPU within normal range, no action needed"
    fi
    
    log "Auto-scaling check completed"
}

main "$@"
EOF
}

# å…¨é‹ç”¨è¨­å®šç”Ÿæˆ
generate_all() {
    log_info "å…¨ã¦ã®é‹ç”¨è¨­å®šã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."
    
    load_project_info
    
    # å„ç¨®è¨­å®šã‚’ç”Ÿæˆ
    generate_monitoring "$MONITORING_LEVEL"
    generate_alerting "$SLO"
    generate_logging
    generate_backup
    generate_runbooks
    generate_automation
    
    # ãƒã‚¹ã‚¿ãƒ¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
    generate_ops_master_doc
    
    log_success "å…¨é‹ç”¨è¨­å®šç”Ÿæˆå®Œäº†"
}

# é‹ç”¨ãƒã‚¹ã‚¿ãƒ¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
generate_ops_master_doc() {
    cat > "$OUTPUT_DIR/operations-guide.md" << EOF
# é‹ç”¨ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: $(basename "$(pwd)")
- **SLO**: $SLO
- **ç›£è¦–ãƒ¬ãƒ™ãƒ«**: $MONITORING_LEVEL
- **ãƒ‡ãƒ—ãƒ­ã‚¤ç¨®åˆ¥**: $DEPLOYMENT_TYPE

## ç”Ÿæˆã•ã‚ŒãŸè¨­å®š

### ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ
- [x] CloudWatch è¨­å®š
- [x] ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«
- [x] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š
- [x] PagerDuty çµ±åˆ

### ãƒ­ã‚°ç®¡ç†
- [x] ãƒ­ã‚°åé›†è¨­å®š
- [x] ãƒ­ã‚°ãƒ‘ãƒ¼ã‚¹è¨­å®š
- [x] ä¿æŒãƒãƒªã‚·ãƒ¼
- [x] ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–è¨­å®š

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»DR
- [x] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨ˆç”»
- [x] è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- [x] å¾©å…ƒæ‰‹é †
- [x] ç½å®³å¾©æ—§è¨ˆç”»

### é‹ç”¨è‡ªå‹•åŒ–
- [x] ãƒ‡ãƒ—ãƒ­ã‚¤è‡ªå‹•åŒ–
- [x] ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è‡ªå‹•åŒ–
- [x] å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
- [x] éšœå®³å¾©æ—§è‡ªå‹•åŒ–

### ãƒ©ãƒ³ãƒ–ãƒƒã‚¯
- [x] ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ
- [x] ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- [x] å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ‰‹é †

## é‹ç”¨ãƒ—ãƒ­ã‚»ã‚¹

### æ—¥æ¬¡ã‚¿ã‚¹ã‚¯
- [ ] ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèªãƒ»å¯¾å¿œ
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹ç¢ºèª
- [ ] ã‚³ã‚¹ãƒˆç¢ºèª

### é€±æ¬¡ã‚¿ã‚¹ã‚¯
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒé©ç”¨
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
- [ ] ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°

### æœˆæ¬¡ã‚¿ã‚¹ã‚¯
- [ ] SLOãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] ã‚³ã‚¹ãƒˆæœ€é©åŒ–
- [ ] ç½å®³å¾©æ—§ãƒ†ã‚¹ãƒˆ

## SLO/SLI è¨­å®š

### å¯ç”¨æ€§ SLO: $SLO
- **æ¸¬å®šæœŸé–“**: 30æ—¥é–“
- **ã‚¨ãƒ©ãƒ¼ãƒã‚¸ã‚§ãƒƒãƒˆ**: $(calculate_error_budget "$SLO")
- **ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤**: ã‚¨ãƒ©ãƒ¼ãƒã‚¸ã‚§ãƒƒãƒˆã®50%æ¶ˆè²»æ™‚

### ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ  SLO: ${RESPONSE_TIME}ç§’
- **æ¸¬å®šå¯¾è±¡**: 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
- **æ¸¬å®šæœŸé–“**: 30æ—¥é–“
- **ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤**: SLOé•åç‡ > 5%

## ç·Šæ€¥é€£çµ¡å…ˆ

### ã‚ªãƒ³ã‚³ãƒ¼ãƒ«ä½“åˆ¶
- **å¹³æ—¥ (9:00-18:00)**: ãƒãƒ¼ãƒ å…¨å“¡
- **å¹³æ—¥å¤œé–“ãƒ»ä¼‘æ—¥**: ã‚ªãƒ³ã‚³ãƒ¼ãƒ«æ‹…å½“è€…
- **ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ â†’ CTO

### å¤–éƒ¨ãƒ™ãƒ³ãƒ€ãƒ¼
- **AWS ã‚µãƒãƒ¼ãƒˆ**: [ã‚µãƒãƒ¼ãƒˆã‚±ãƒ¼ã‚¹](https://console.aws.amazon.com/support/)
- **PagerDuty**: support@pagerduty.com
- **ç¬¬ä¸‰è€…ç›£è¦–**: å„ãƒ™ãƒ³ãƒ€ãƒ¼ã‚µãƒãƒ¼ãƒˆ

## ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

### ç›£è¦–
- [CloudWatch Dashboard](https://console.aws.amazon.com/cloudwatch/)
- [Custom Dashboard](http://monitoring.company.com/)

### ãƒ­ã‚°
- [CloudWatch Logs](https://console.aws.amazon.com/cloudwatch/logs)
- [Log Analysis](http://logs.company.com/)

### ã‚¢ãƒ©ãƒ¼ãƒˆ
- [PagerDuty](https://company.pagerduty.com/)
- [Slack #alerts](https://company.slack.com/channels/alerts)

## æ”¹å–„è¨ˆç”»

### çŸ­æœŸ (1-3ãƒ¶æœˆ)
- [ ] ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç²¾åº¦å‘ä¸Š
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆç²¾åº¦å‘ä¸Šï¼ˆãƒã‚¤ã‚ºå‰Šæ¸›ï¼‰
- [ ] è‡ªå‹•å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¿½åŠ 

### ä¸­æœŸ (3-6ãƒ¶æœˆ)
- [ ] ã‚«ã‚ªã‚¹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å°å…¥
- [ ] äºˆæ¸¬çš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Ÿè£…
- [ ] é«˜åº¦ãªãƒ­ã‚°åˆ†æ

### é•·æœŸ (6-12ãƒ¶æœˆ)
- [ ] AI/ML ã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥
- [ ] å®Œå…¨ãªè‡ªå·±ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ 
- [ ] ãƒãƒ«ãƒãƒªãƒ¼ã‚¸ãƒ§ãƒ³å¯¾å¿œ
EOF
}

# ã‚¨ãƒ©ãƒ¼ãƒã‚¸ã‚§ãƒƒãƒˆè¨ˆç®—
calculate_error_budget() {
    local slo="$1"
    case "$slo" in
        "99.0%") echo "1.0%" ;;
        "99.9%") echo "0.1%" ;;
        "99.95%") echo "0.05%" ;;
        "99.99%") echo "0.01%" ;;
        *) echo "0.1%" ;;
    esac
}

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
main() {
    echo "ğŸ”§ $AGENT_NAME v$AGENT_VERSION"
    echo "============================="
    
    # åˆæœŸåŒ–
    init_sre
    
    # å¼•æ•°ã®å‡¦ç†
    case "$1" in
        --monitoring)
            shift
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    --level)
                        generate_monitoring "$2"
                        shift 2
                        ;;
                    *)
                        generate_monitoring
                        shift
                        ;;
                esac
            done
            ;;
        --alerting)
            shift
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    --slo)
                        generate_alerting "$2"
                        shift 2
                        ;;
                    *)
                        generate_alerting
                        shift
                        ;;
                esac
            done
            ;;
        --logging)
            generate_logging
            ;;
        --backup)
            generate_backup
            ;;
        --runbooks)
            generate_runbooks
            ;;
        --automation)
            generate_automation
            ;;
        --all)
            generate_all
            ;;
        --help|"")
            show_usage
            ;;
        *)
            log_error "ä¸æ˜ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³: $1"
            show_usage
            exit 1
            ;;
    esac
}

# å®Ÿè¡Œ
main "$@"