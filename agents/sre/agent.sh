#!/bin/bash
# SRE Agent - ÈÅãÁî®„ÉªÁõ£Ë¶ñ„ÉªËá™ÂãïÂåñ„Ç®„Éº„Ç∏„Çß„É≥„Éà

# Ë®≠ÂÆö
AGENT_NAME="SRE Agent"
AGENT_VERSION="1.0.0"
REQUIREMENTS_DIR="../requirements"
ARCHITECTURE_DIR="../architecture"
AWS_DIR="../aws"
OUTPUT_DIR="../ops"
TEMPLATES_DIR="templates/sre"

# „É≠„Ç∞Èñ¢Êï∞
log_info() {
    echo -e "\033[1;34m[INFO]\033[0m $1"
}

log_success() {
    echo -e "\033[1;32m[SUCCESS]\033[0m $1"
}

log_error() {
    echo -e "\033[1;31m[ERROR]\033[0m $1"
}

log_warn() {
    echo -e "\033[1;33m[WARN]\033[0m $1"
}

# ‰ΩøÁî®ÊñπÊ≥ï„ÅÆË°®Á§∫
show_usage() {
    cat << EOF
üîß SRE Agent v${AGENT_VERSION}
=============================

‰ΩøÁî®ÊñπÊ≥ï:
  $0 [„Ç™„Éó„Ç∑„Éß„É≥]

„Ç™„Éó„Ç∑„Éß„É≥:
  --monitoring       Áõ£Ë¶ñË®≠ÂÆö„ÇíÁîüÊàê
  --alerting         „Ç¢„É©„Éº„ÉàË®≠ÂÆö„ÇíÁîüÊàê
  --logging          „É≠„Ç∞Ë®≠ÂÆö„ÇíÁîüÊàê
  --backup           „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÊà¶Áï•„ÇíÁîüÊàê
  --disaster         ÁÅΩÂÆ≥Âæ©ÊóßË®àÁîª„ÇíÁîüÊàê
  --runbooks         „É©„É≥„Éñ„ÉÉ„ÇØ„ÇíÁîüÊàê
  --automation       ÈÅãÁî®Ëá™ÂãïÂåñ„Çπ„ÇØ„É™„Éó„Éà„ÇíÁîüÊàê
  --security         „Çª„Ç≠„É•„É™„ÉÜ„Ç£Ë®≠ÂÆö„ÇíÁîüÊàê
  --performance      „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÁõ£Ë¶ñ„ÇíÁîüÊàê
  --cost             „Ç≥„Çπ„ÉàÁõ£Ë¶ñ„ÇíÁîüÊàê
  --slo              SLO/SLIË®≠ÂÆö„ÇíÁîüÊàê
  --all              ÂÖ®„Å¶„ÅÆÈÅãÁî®Ë®≠ÂÆö„ÇíÁîüÊàê
  --help             „Åì„ÅÆ„Éò„É´„Éó„ÇíË°®Á§∫

‰æã:
  $0 --monitoring --level standard
  $0 --alerting --slo 99.9
  $0 --runbooks
  $0 --all

EOF
}

# ÂàùÊúüÂåñ
init_sre() {
    log_info "SREÁí∞Â¢É„ÇíÂàùÊúüÂåñ„Åó„Å¶„ÅÑ„Åæ„Åô..."
    
    # „Éá„Ç£„É¨„ÇØ„Éà„É™‰ΩúÊàê
    mkdir -p "$OUTPUT_DIR" logs tmp
    mkdir -p "$OUTPUT_DIR"/{monitoring,alerting,logging,backup,runbooks,automation,security}
    mkdir -p "$OUTPUT_DIR/automation"/{scripts,terraform,ansible}
    
    log_success "SREÁí∞Â¢É„ÅÆÂàùÊúüÂåñÂÆå‰∫Ü"
}

# „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊÉÖÂ†±„ÅÆË™≠„ÅøËæº„Åø
load_project_info() {
    log_info "„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊÉÖÂ†±„ÇíË™≠„ÅøËæº„Çì„Åß„ÅÑ„Åæ„Åô..."
    
    # Ë¶Å‰ª∂ÂÆöÁæ©„Åã„ÇâÊÉÖÂ†±„ÇíÂèñÂæó
    if [ -f "$REQUIREMENTS_DIR/requirements.md" ]; then
        SLO=$(grep -o "ÂèØÁî®ÊÄßÁõÆÊ®ô.*[0-9]\+\.[0-9]\+%" "$REQUIREMENTS_DIR/requirements.md" | grep -o "[0-9]\+\.[0-9]\+%" | head -1)
        CONCURRENT_USERS=$(grep -o "ÊÉ≥ÂÆö„É¶„Éº„Ç∂„ÉºÊï∞.*[0-9]\+" "$REQUIREMENTS_DIR/requirements.md" | grep -o "[0-9]\+" | head -1)
        RESPONSE_TIME=$(grep -o "„É¨„Çπ„Éù„É≥„Çπ„Çø„Ç§„É†.*[0-9]\+" "$REQUIREMENTS_DIR/requirements.md" | grep -o "[0-9]\+" | head -1)
        COST_LIMIT=$(grep -o "„Ç≥„Çπ„Éà‰∏äÈôê.*[0-9]\+" "$REQUIREMENTS_DIR/requirements.md" | grep -o "[0-9]\+" | head -1)
    fi
    
    # „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Åã„ÇâÊÉÖÂ†±„ÇíÂèñÂæó
    if [ -f "$ARCHITECTURE_DIR/design.md" ]; then
        if grep -qi "serverless\|lambda" "$ARCHITECTURE_DIR/design.md"; then
            DEPLOYMENT_TYPE="serverless"
        elif grep -qi "container\|ecs\|docker" "$ARCHITECTURE_DIR/design.md"; then
            DEPLOYMENT_TYPE="container"
        else
            DEPLOYMENT_TYPE="traditional"
        fi
    fi
    
    # „Éá„Éï„Ç©„É´„ÉàÂÄ§Ë®≠ÂÆö
    SLO=${SLO:-"99.9%"}
    CONCURRENT_USERS=${CONCURRENT_USERS:-1000}
    RESPONSE_TIME=${RESPONSE_TIME:-2}
    COST_LIMIT=${COST_LIMIT:-500}
    DEPLOYMENT_TYPE=${DEPLOYMENT_TYPE:-"traditional"}
    
    # SLO„Å´Âü∫„Å•„ÅèÁõ£Ë¶ñ„É¨„Éô„É´Ê±∫ÂÆö
    case "$SLO" in
        "99.0%") MONITORING_LEVEL="basic" ;;
        "99.9%") MONITORING_LEVEL="standard" ;;
        "99.95%"|"99.99%") MONITORING_LEVEL="advanced" ;;
        *) MONITORING_LEVEL="standard" ;;
    esac
    
    log_success "„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊÉÖÂ†±Ë™≠„ÅøËæº„ÅøÂÆå‰∫Ü"
    log_info "SLO: $SLO, Áõ£Ë¶ñ„É¨„Éô„É´: $MONITORING_LEVEL, „Éá„Éó„É≠„Ç§Á®ÆÂà•: $DEPLOYMENT_TYPE"
}

# Áõ£Ë¶ñË®≠ÂÆöÁîüÊàê
generate_monitoring() {
    local level="$1"
    level=${level:-$MONITORING_LEVEL}
    
    log_info "Áõ£Ë¶ñË®≠ÂÆö„ÇíÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô: $level"
    
    load_project_info
    
    # CloudWatchË®≠ÂÆö
    generate_cloudwatch_config "$level"
    
    # „Ç´„Çπ„Çø„É†„É°„Éà„É™„ÇØ„Çπ
    generate_custom_metrics "$level"
    
    # „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ
    generate_dashboard_config "$level"
    
    # Áõ£Ë¶ñË®àÁîªÊõ∏
    generate_monitoring_plan "$level"
    
    log_success "Áõ£Ë¶ñË®≠ÂÆöÁîüÊàêÂÆå‰∫Ü"
}

# CloudWatchË®≠ÂÆöÁîüÊàê
generate_cloudwatch_config() {
    local level="$1"
    
    cat > "$OUTPUT_DIR/monitoring/cloudwatch.yaml" << EOF
# CloudWatch Áõ£Ë¶ñË®≠ÂÆö
AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudWatch monitoring configuration'

Parameters:
  Environment:
    Type: String
    Default: prod
  AlertEmail:
    Type: String
    Description: Email for alerts

Resources:
  # SNS Topic for alerts
  AlertTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub \${Environment}-alerts
      Subscription:
        - Protocol: email
          Endpoint: !Ref AlertEmail

  # CloudWatch Dashboard
  MonitoringDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub \${Environment}-monitoring
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "properties": {
                "metrics": [
                  ["AWS/ApplicationELB", "RequestCount"],
                  ["AWS/ApplicationELB", "TargetResponseTime"],
                  ["AWS/ApplicationELB", "HTTPCode_Target_4XX_Count"],
                  ["AWS/ApplicationELB", "HTTPCode_Target_5XX_Count"]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "us-east-1",
                "title": "Load Balancer Metrics"
              }
            },
$(generate_additional_widgets "$level")
          ]
        }

  # Basic Alarms
$(generate_basic_alarms "$level")

$(if [ "$level" != "basic" ]; then
    echo "  # Advanced Alarms"
    generate_advanced_alarms "$level"
fi)

Outputs:
  DashboardURL:
    Description: CloudWatch Dashboard URL
    Value: !Sub "https://console.aws.amazon.com/cloudwatch/home?region=\${AWS::Region}#dashboards:name=\${MonitoringDashboard}"
EOF
}

# Âü∫Êú¨„Ç¢„É©„Éº„É†ÁîüÊàê
generate_basic_alarms() {
    local level="$1"
    
    cat << 'EOF'
  # High CPU Alarm
  HighCPUAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${Environment}-high-cpu
      AlarmDescription: High CPU utilization detected
      MetricName: CPUUtilization
      Namespace: AWS/EC2
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 80
      ComparisonOperator: GreaterThanThreshold
      AlarmActions:
        - !Ref AlertTopic

  # High Memory Alarm
  HighMemoryAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${Environment}-high-memory
      AlarmDescription: High memory utilization detected
      MetricName: MemoryUtilization
      Namespace: CWAgent
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 85
      ComparisonOperator: GreaterThanThreshold
      AlarmActions:
        - !Ref AlertTopic

  # HTTP 5xx Errors
  HTTP5xxAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${Environment}-http-5xx-errors
      AlarmDescription: High rate of 5xx errors
      MetricName: HTTPCode_Target_5XX_Count
      Namespace: AWS/ApplicationELB
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 2
      Threshold: 10
      ComparisonOperator: GreaterThanThreshold
      AlarmActions:
        - !Ref AlertTopic
EOF
}

# „Ç¢„É©„Éº„ÉàË®≠ÂÆöÁîüÊàê
generate_alerting() {
    local slo="$1"
    slo=${slo:-$SLO}
    
    log_info "„Ç¢„É©„Éº„ÉàË®≠ÂÆö„ÇíÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô: SLO $slo"
    
    load_project_info
    
    # „Ç¢„É©„Éº„Éà„É´„Éº„É´
    generate_alert_rules "$slo"
    
    # PagerDutyË®≠ÂÆö
    generate_pagerduty_config
    
    # SlackË®≠ÂÆö
    generate_slack_config
    
    # „Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥Ë®≠ÂÆö
    generate_escalation_policy "$slo"
    
    log_success "„Ç¢„É©„Éº„ÉàË®≠ÂÆöÁîüÊàêÂÆå‰∫Ü"
}

# „Ç¢„É©„Éº„Éà„É´„Éº„É´ÁîüÊàê
generate_alert_rules() {
    local slo="$1"
    
    # SLO„Å´Âü∫„Å•„ÅèÈñæÂÄ§Ë®àÁÆó
    local error_budget
    case "$slo" in
        "99.0%") error_budget="1.0" ;;
        "99.9%") error_budget="0.1" ;;
        "99.95%") error_budget="0.05" ;;
        "99.99%") error_budget="0.01" ;;
        *) error_budget="0.1" ;;
    esac
    
    cat > "$OUTPUT_DIR/alerting/alert-rules.yaml" << EOF
# „Ç¢„É©„Éº„Éà„É´„Éº„É´Ë®≠ÂÆö
groups:
  - name: slo-alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > $error_budget
        for: 5m
        labels:
          severity: critical
          slo: availability
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ \$value | humanizePercentage }} which exceeds SLO of $slo"

      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > $RESPONSE_TIME
        for: 5m
        labels:
          severity: warning
          slo: latency
        annotations:
          summary: "High latency detected"
          description: "95th percentile latency is {{ \$value }}s which exceeds target of ${RESPONSE_TIME}s"

      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          slo: availability
        annotations:
          summary: "Service is down"
          description: "{{ \$labels.instance }} has been down for more than 1 minute"

  - name: infrastructure-alerts
    rules:
      - alert: HighCPU
        expr: cpu_usage_percent > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ \$value }}% on {{ \$labels.instance }}"

      - alert: HighMemory
        expr: memory_usage_percent > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ \$value }}% on {{ \$labels.instance }}"

      - alert: DiskSpaceLow
        expr: disk_free_percent < 15
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space"
          description: "Disk space is {{ \$value }}% free on {{ \$labels.instance }}"

  - name: database-alerts
    rules:
      - alert: DatabaseConnectionsHigh
        expr: database_connections_active / database_connections_max > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database connection usage is {{ \$value | humanizePercentage }}"

      - alert: DatabaseSlowQueries
        expr: rate(database_slow_queries_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow database queries detected"
          description: "Slow query rate is {{ \$value }} per second"

  - name: cost-alerts
    rules:
      - alert: HighCost
        expr: aws_billing_estimated_charges > $COST_LIMIT
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "High AWS costs"
          description: "AWS costs are \${{ \$value }} which exceeds budget of \$$COST_LIMIT"
EOF
}

# „É≠„Ç∞Ë®≠ÂÆöÁîüÊàê
generate_logging() {
    log_info "„É≠„Ç∞Ë®≠ÂÆö„ÇíÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô..."
    
    load_project_info
    
    # „É≠„Ç∞ÂèéÈõÜË®≠ÂÆö
    generate_log_collection_config
    
    # „É≠„Ç∞„Éë„Éº„ÇπË®≠ÂÆö
    generate_log_parsing_config
    
    # „É≠„Ç∞‰øùÊåÅ„Éù„É™„Ç∑„Éº
    generate_log_retention_policy
    
    # „É≠„Ç∞„Ç¢„Éº„Ç´„Ç§„ÉñË®≠ÂÆö
    generate_log_archive_config
    
    log_success "„É≠„Ç∞Ë®≠ÂÆöÁîüÊàêÂÆå‰∫Ü"
}

# „É≠„Ç∞ÂèéÈõÜË®≠ÂÆöÁîüÊàê
generate_log_collection_config() {
    case "$DEPLOYMENT_TYPE" in
        "container")
            generate_container_logging
            ;;
        "serverless")
            generate_serverless_logging
            ;;
        *)
            generate_traditional_logging
            ;;
    esac
}

# „Ç≥„É≥„ÉÜ„Éä„É≠„ÇÆ„É≥„Ç∞Ë®≠ÂÆö
generate_container_logging() {
    cat > "$OUTPUT_DIR/logging/fluentd.conf" << 'EOF'
# Fluentd configuration for container logging

<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<source>
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  format json
  read_from_head true
</source>

# Parse application logs
<filter kubernetes.**>
  @type kubernetes_metadata
</filter>

<filter kubernetes.**>
  @type parser
  key_name log
  reserve_data true
  remove_key_name_field true
  <parse>
    @type multi_format
    <pattern>
      format json
    </pattern>
    <pattern>
      format none
    </pattern>
  </parse>
</filter>

# Add severity based on log level
<filter kubernetes.**>
  @type record_transformer
  <record>
    severity ${record.dig("level") == "error" ? "ERROR" : record.dig("level") == "warn" ? "WARNING" : "INFO"}
  </record>
</filter>

# Output to CloudWatch Logs
<match kubernetes.**>
  @type cloudwatch_logs
  log_group_name /aws/containerinsights/#{ENV['CLUSTER_NAME']}/application
  log_stream_name_key stream_name
  auto_create_stream true
  remove_log_stream_name_key true
  <buffer>
    flush_interval 5s
    chunk_limit_size 2m
    queued_chunks_limit_size 32
  </buffer>
</match>

# Output errors to separate stream
<match **>
  @type copy
  <store>
    @type cloudwatch_logs
    log_group_name /aws/application/logs
    log_stream_name general
    auto_create_stream true
  </store>
  <store>
    @type stdout
  </store>
</match>
EOF
}

# „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÊà¶Áï•ÁîüÊàê
generate_backup() {
    log_info "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÊà¶Áï•„ÇíÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô..."
    
    load_project_info
    
    # „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóË®àÁîª
    generate_backup_plan
    
    # Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Çπ„ÇØ„É™„Éó„Éà
    generate_backup_scripts
    
    # Âæ©ÂÖÉÊâãÈ†Ü
    generate_restore_procedures
    
    # „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÉÜ„Çπ„ÉàË®àÁîª
    generate_backup_testing_plan
    
    log_success "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÊà¶Áï•ÁîüÊàêÂÆå‰∫Ü"
}

# „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóË®àÁîªÁîüÊàê
generate_backup_plan() {
    cat > "$OUTPUT_DIR/backup/backup-plan.md" << EOF
# „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóË®àÁîª

## Ê¶ÇË¶Å
- **SLO**: $SLO
- **RTO (Recovery Time Objective)**: $(calculate_rto "$SLO")
- **RPO (Recovery Point Objective)**: $(calculate_rpo "$SLO")

## „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂØæË±°

### „Éá„Éº„Çø„Éô„Éº„Çπ
- **È†ªÂ∫¶**: Êó•Ê¨°„Éï„É´„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó + Á∂ôÁ∂öÁöÑ„É≠„Ç∞„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
- **‰øùÊåÅÊúüÈñì**: 30Êó•Èñì
- **ÊöóÂè∑Âåñ**: AES-256
- **„ÉÜ„Çπ„ÉàÈ†ªÂ∫¶**: ÈÄ±Ê¨°

### „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Éï„Ç°„Ç§„É´
- **È†ªÂ∫¶**: Êó•Ê¨°
- **‰øùÊåÅÊúüÈñì**: 7Êó•Èñì
- **ÂØæË±°**: Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÄÅ„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Éï„Ç°„Ç§„É´

### Ë®≠ÂÆö„ÉªInfrastructure as Code
- **È†ªÂ∫¶**: Â§âÊõ¥ÊôÇÔºàGitÁÆ°ÁêÜÔºâ
- **‰øùÊåÅÊúüÈñì**: ÁÑ°ÊúüÈôê
- **ÂØæË±°**: CloudFormation„ÄÅË®≠ÂÆö„Éï„Ç°„Ç§„É´

## „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Çπ„Ç±„Ç∏„É•„Éº„É´

| ÂØæË±° | È†ªÂ∫¶ | ÊôÇÂàª | ‰øùÊåÅÊúüÈñì | ÊöóÂè∑Âåñ |
|------|------|------|----------|--------|
| RDS | Êó•Ê¨° | 03:00 UTC | 30Êó• | ‚úÖ |
| S3 | Á∂ôÁ∂öÁöÑ | - | 30Êó• | ‚úÖ |
| EBS | Êó•Ê¨° | 04:00 UTC | 7Êó• | ‚úÖ |
| Config | Â§âÊõ¥ÊôÇ | - | Ê∞∏Á∂ö | ‚úÖ |

## ÁÅΩÂÆ≥Âæ©Êóß„Ç∑„Éä„É™„Ç™

### „Ç∑„Éä„É™„Ç™1: „Éá„Éº„Çø„Éô„Éº„ÇπÈöúÂÆ≥
- **RTO**: $(calculate_rto "$SLO")
- **RPO**: 15ÂàÜ
- **ÊâãÈ†Ü**: RDSËá™Âãï„Éï„Çß„Ç§„É´„Ç™„Éº„Éê„Éº

### „Ç∑„Éä„É™„Ç™2: AZÈöúÂÆ≥
- **RTO**: $(calculate_rto "$SLO")  
- **RPO**: 15ÂàÜ
- **ÊâãÈ†Ü**: Multi-AZËá™ÂãïÂàá„ÇäÊõø„Åà

### „Ç∑„Éä„É™„Ç™3: „É™„Éº„Ç∏„Éß„É≥ÈöúÂÆ≥
- **RTO**: 4ÊôÇÈñì
- **RPO**: 1ÊôÇÈñì
- **ÊâãÈ†Ü**: ÊâãÂãï„ÇØ„É≠„Çπ„É™„Éº„Ç∏„Éß„É≥Âæ©ÂÖÉ

## Âæ©ÂÖÉÊâãÈ†Ü

### „Éá„Éº„Çø„Éô„Éº„ÇπÂæ©ÂÖÉ
\`\`\`bash
# Point-in-time recovery
aws rds restore-db-instance-to-point-in-time \\
  --target-db-instance-identifier mydb-restored \\
  --source-db-instance-identifier mydb \\
  --restore-time 2023-01-01T12:00:00Z

# „Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„Éà„Åã„Çâ„ÅÆÂæ©ÂÖÉ
aws rds restore-db-instance-from-db-snapshot \\
  --db-instance-identifier mydb-restored \\
  --db-snapshot-identifier mydb-snapshot-20230101
\`\`\`

### „Éï„Ç°„Ç§„É´Âæ©ÂÖÉ
\`\`\`bash
# S3„Åã„Çâ„ÅÆÂæ©ÂÖÉ
aws s3 sync s3://backup-bucket/latest/ ./restore/

# EBS„Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„Éà„Åã„Çâ„ÅÆÂæ©ÂÖÉ
aws ec2 create-volume --snapshot-id snap-12345678 \\
  --availability-zone us-east-1a
\`\`\`

## „ÉÜ„Çπ„ÉàË®àÁîª

### ÈÄ±Ê¨°„ÉÜ„Çπ„Éà
- „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆåÊï¥ÊÄß„ÉÅ„Çß„ÉÉ„ÇØ
- Â∞èË¶èÊ®°Âæ©ÂÖÉ„ÉÜ„Çπ„Éà

### ÊúàÊ¨°„ÉÜ„Çπ„Éà
- „Éï„É´Âæ©ÂÖÉ„ÉÜ„Çπ„ÉàÔºàdevÁí∞Â¢ÉÔºâ
- Âæ©ÊóßÊôÇÈñìÊ∏¨ÂÆö

### ÂõõÂçäÊúü„ÉÜ„Çπ„Éà
- ÁÅΩÂÆ≥Âæ©ÊóßË®ìÁ∑¥
- „ÇØ„É≠„Çπ„É™„Éº„Ç∏„Éß„É≥Âæ©ÂÖÉ

## Áõ£Ë¶ñ„Éª„Ç¢„É©„Éº„Éà

### „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÁõ£Ë¶ñ
- „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÊàêÂäü/Â§±Êïó
- „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Çµ„Ç§„Ç∫Áï∞Â∏∏
- Âæ©ÂÖÉ„ÉÜ„Çπ„ÉàÁµêÊûú

### „Ç¢„É©„Éº„ÉàË®≠ÂÆö
- „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂ§±ÊïóÊôÇ: Âç≥Â∫ß„Å´„Ç¢„É©„Éº„Éà
- RPO/RTOË∂ÖÈÅéÊôÇ: „Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥
- „ÉÜ„Çπ„ÉàÂ§±ÊïóÊôÇ: ÁøåÂñ∂Ê•≠Êó•ÂØæÂøú
EOF
}

# RTOË®àÁÆó
calculate_rto() {
    local slo="$1"
    case "$slo" in
        "99.0%") echo "4ÊôÇÈñì" ;;
        "99.9%") echo "1ÊôÇÈñì" ;;
        "99.95%") echo "30ÂàÜ" ;;
        "99.99%") echo "15ÂàÜ" ;;
        *) echo "1ÊôÇÈñì" ;;
    esac
}

# RPOË®àÁÆó
calculate_rpo() {
    local slo="$1"
    case "$slo" in
        "99.0%") echo "1ÊôÇÈñì" ;;
        "99.9%") echo "15ÂàÜ" ;;
        "99.95%") echo "5ÂàÜ" ;;
        "99.99%") echo "1ÂàÜ" ;;
        *) echo "15ÂàÜ" ;;
    esac
}

# „É©„É≥„Éñ„ÉÉ„ÇØÁîüÊàê
generate_runbooks() {
    log_info "„É©„É≥„Éñ„ÉÉ„ÇØ„ÇíÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô..."
    
    load_project_info
    
    # „Ç§„É≥„Ç∑„Éá„É≥„ÉàÂØæÂøú„É©„É≥„Éñ„ÉÉ„ÇØ
    generate_incident_runbooks
    
    # ÂÆöÊúü„É°„É≥„ÉÜ„Éä„É≥„ÇπÊâãÈ†Ü
    generate_maintenance_runbooks
    
    # „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞„Ç¨„Ç§„Éâ
    generate_troubleshooting_guide
    
    log_success "„É©„É≥„Éñ„ÉÉ„ÇØÁîüÊàêÂÆå‰∫Ü"
}

# „Ç§„É≥„Ç∑„Éá„É≥„ÉàÂØæÂøú„É©„É≥„Éñ„ÉÉ„ÇØ
generate_incident_runbooks() {
    cat > "$OUTPUT_DIR/runbooks/incident-response.md" << 'EOF'
# „Ç§„É≥„Ç∑„Éá„É≥„ÉàÂØæÂøú„É©„É≥„Éñ„ÉÉ„ÇØ

## Ê¶ÇË¶Å
„Ç∑„Çπ„ÉÜ„É†„Ç§„É≥„Ç∑„Éá„É≥„ÉàÁô∫ÁîüÊôÇ„ÅÆÂØæÂøúÊâãÈ†Ü„ÇíÂÆöÁæ©„Åô„Çã„ÄÇ

## „Ç§„É≥„Ç∑„Éá„É≥„ÉàÂàÜÈ°û

### Severity 1 (Critical)
- **ÂÆöÁæ©**: „Çµ„Éº„Éì„ÇπÂÆåÂÖ®ÂÅúÊ≠¢„ÄÅÈáçÂ§ß„Å™„Çª„Ç≠„É•„É™„ÉÜ„Ç£‰æµÂÆ≥
- **ÂØæÂøúÊôÇÈñì**: 15ÂàÜ‰ª•ÂÜÖ„Å´ÂàùÊúüÂØæÂøú
- **„Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥**: Âç≥Â∫ß„Å´„Éû„Éç„Éº„Ç∏„É£„Éº„Å´Â†±Âëä

### Severity 2 (High)
- **ÂÆöÁæ©**: Ê©üËÉΩ„ÅÆ‰∏ÄÈÉ®ÂÅúÊ≠¢„ÄÅÈáçÂ§ß„Å™ÊÄßËÉΩÂä£Âåñ
- **ÂØæÂøúÊôÇÈñì**: 1ÊôÇÈñì‰ª•ÂÜÖ„Å´ÂàùÊúüÂØæÂøú
- **„Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥**: 2ÊôÇÈñì‰ª•ÂÜÖ„Å´„Éû„Éç„Éº„Ç∏„É£„Éº„Å´Â†±Âëä

### Severity 3 (Medium)
- **ÂÆöÁæ©**: ËªΩÂæÆ„Å™Ê©üËÉΩ‰∏çÂÖ∑Âêà„ÄÅËªΩÂæÆ„Å™ÊÄßËÉΩÂïèÈ°å
- **ÂØæÂøúÊôÇÈñì**: 4ÊôÇÈñì‰ª•ÂÜÖ„Å´ÂàùÊúüÂØæÂøú
- **„Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥**: ÁøåÂñ∂Ê•≠Êó•„Å´„Éû„Éç„Éº„Ç∏„É£„Éº„Å´Â†±Âëä

## ÂØæÂøú„Éï„É≠„Éº

### 1. „Ç§„É≥„Ç∑„Éá„É≥„ÉàÊ§úÁü•
```mermaid
graph TD
    A[„Ç¢„É©„Éº„ÉàÂèó‰ø°] --> B[ÈáçË¶ÅÂ∫¶Âà§ÂÆö]
    B --> C{Severity 1?}
    C -->|Yes| D[Âç≥Â∫ß„Å´„Ç™„É≥„Ç≥„Éº„É´]
    C -->|No| E[ÈÄöÂ∏∏ÂØæÂøúÈñãÂßã]
    D --> F[Êà¶ÊôÇÊÖãÂã¢ÈñãÂßã]
    E --> G[Ë™øÊüªÈñãÂßã]
    F --> G
```

### 2. ÂàùÊúüÂØæÂøúÊâãÈ†Ü

#### Step 1: Áä∂Ê≥ÅÁ¢∫Ë™ç (5ÂàÜ)
```bash
# „Çµ„Éº„Éì„ÇπÁä∂ÊÖãÁ¢∫Ë™ç
curl -I https://api.example.com/health

# ‰∏ªË¶Å„É°„Éà„É™„ÇØ„ÇπÁ¢∫Ë™ç
aws cloudwatch get-metric-statistics \
  --namespace AWS/ApplicationELB \
  --metric-name TargetResponseTime \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Average

# „Ç®„É©„Éº„É≠„Ç∞Á¢∫Ë™ç
aws logs filter-log-events \
  --log-group-name /aws/lambda/api \
  --start-time $(date -d '1 hour ago' +%s)000 \
  --filter-pattern 'ERROR'
```

#### Step 2: ÂΩ±ÈüøÁØÑÂõ≤ÁâπÂÆö (10ÂàÜ)
- ÂΩ±Èüø„ÇíÂèó„Åë„Å¶„ÅÑ„Çã„É¶„Éº„Ç∂„ÉºÊï∞
- ÂΩ±Èüø„ÇíÂèó„Åë„Å¶„ÅÑ„ÇãÊ©üËÉΩ
- Âú∞ÁêÜÁöÑ„Å™ÂΩ±ÈüøÁØÑÂõ≤
- „ÉÄ„Ç¶„É≥„Çπ„Éà„É™„Éº„É†„Çµ„Éº„Éì„Çπ„Å∏„ÅÆÂΩ±Èüø

#### Step 3: ‰∏ÄÊôÇÁöÑÂõûÈÅøÁ≠ñ (15ÂàÜ)
```bash
# „Éà„É©„Éï„Ç£„ÉÉ„ÇØÂà∂Èôê
aws elbv2 modify-target-group \
  --target-group-arn arn:aws:elasticloadbalancing:... \
  --health-check-interval-seconds 10

# Á∑äÊÄ•„É°„É≥„ÉÜ„Éä„É≥„Çπ„Éö„Éº„Ç∏Ë°®Á§∫
aws s3 cp maintenance.html s3://cdn-bucket/index.html

# Auto ScalingË™øÊï¥
aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name web-asg \
  --desired-capacity 10
```

### 3. Ê†πÊú¨ÂéüÂõ†ÂàÜÊûê

#### „Éá„Éº„ÇøÂèéÈõÜ
- „Ç∑„Çπ„ÉÜ„É†„É°„Éà„É™„ÇØ„Çπ
- „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„É≠„Ç∞
- Â§ñÈÉ®‰æùÂ≠òÈñ¢‰øÇ„ÅÆÁä∂ÊÖã
- ÊúÄËøë„ÅÆ„Éá„Éó„É≠„Ç§Â±•Ê≠¥

#### ÂàÜÊûêÊâãÊ≥ï
1. **TimelineÂàÜÊûê**: ÂïèÈ°åÁô∫ÁîüÂâçÂæå„ÅÆÂ§âÊõ¥ÁÇπ
2. **5 Whys**: Ê†πÊú¨ÂéüÂõ†„ÅÆÊ∑±Êéò„Çä
3. **Fishbone diagram**: Ë¶ÅÂõ†„ÅÆ‰ΩìÁ≥ªÂåñ

### 4. Âæ©ÊóßÊâãÈ†Ü

#### „Éá„Éº„Çø„Éô„Éº„ÇπÈñ¢ÈÄ£
```bash
# Êé•Á∂öÊï∞Á¢∫Ë™ç
aws rds describe-db-instances \
  --db-instance-identifier production-db

# „Çπ„É≠„Éº„ÇØ„Ç®„É™Á¢∫Ë™ç
mysql -h $DB_HOST -u $DB_USER -p$DB_PASS \
  -e "SHOW PROCESSLIST;"

# Á∑äÊÄ•ÊôÇ„ÅÆRead ReplicaÊòáÊ†º
aws rds promote-read-replica \
  --db-instance-identifier production-db-replica
```

#### „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Èñ¢ÈÄ£
```bash
# „Ç≥„É≥„ÉÜ„ÉäÂÜçËµ∑Âãï
aws ecs update-service \
  --cluster production \
  --service web-service \
  --force-new-deployment

# Ââç„Éê„Éº„Ç∏„Éß„É≥„Å∏„ÅÆ„É≠„Éº„É´„Éê„ÉÉ„ÇØ
kubectl rollout undo deployment/web-app

# „Ç≠„É£„ÉÉ„Ç∑„É•„ÇØ„É™„Ç¢
redis-cli FLUSHALL
```

### 5. ‰∫ãÂæåÂØæÂøú

#### „Ç§„É≥„Ç∑„Éá„É≥„Éà„É¨„Éù„Éº„Éà‰ΩúÊàê
- **Ê¶ÇË¶Å**: ‰Ωï„ÅåËµ∑„Åç„Åü„Åã
- **ÂΩ±Èüø**: Ë™∞„Å´„ÄÅ„Å©„ÅÆÁ®ãÂ∫¶ÂΩ±Èüø„Åó„Åü„Åã
- **Ê†πÊú¨ÂéüÂõ†**: „Å™„ÅúËµ∑„Åç„Åü„Åã
- **ÂØæÂøú**: ‰Ωï„Çí„Åó„Åü„Åã
- **ÊîπÂñÑÁ≠ñ**: ÂÜçÁô∫Èò≤Ê≠¢„ÅÆ„Åü„ÇÅ„ÅÆÊñΩÁ≠ñ

#### „Éù„Çπ„Éà„É¢„Éº„ÉÜ„É†ÂÆüÊñΩ
- ‰∫ãÂÆü„ÅÆÊï¥ÁêÜÔºàblame-freeÔºâ
- „Éó„É≠„Çª„Çπ„ÅÆÊîπÂñÑÁÇπ
- ÊäÄË°ìÁöÑ„Å™ÊîπÂñÑÁÇπ
- „Ç¢„ÇØ„Ç∑„Éß„É≥„Ç¢„Ç§„ÉÜ„É†„ÅÆË®≠ÂÆö

## ÈÄ£Áµ°ÂÖà

### „Ç™„É≥„Ç≥„Éº„É´
- **Primary**: +81-90-1234-5678
- **Secondary**: +81-90-1234-5679
- **Manager**: +81-90-1234-5680

### „Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥
- **Level 1**: „ÉÅ„Éº„É†„É™„Éº„Éâ
- **Level 2**: „Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞„Éû„Éç„Éº„Ç∏„É£„Éº
- **Level 3**: CTO

## „ÉÑ„Éº„É´„Éª„É™„ÇΩ„Éº„Çπ

### Áõ£Ë¶ñ„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ
- CloudWatch Dashboard: https://console.aws.amazon.com/cloudwatch/
- Grafana: https://grafana.company.com/
- PagerDuty: https://company.pagerduty.com/

### „É≠„Ç∞„Éª„É°„Éà„É™„ÇØ„Çπ
- CloudWatch Logs: https://console.aws.amazon.com/cloudwatch/
- Elasticsearch: https://elasticsearch.company.com/
- Jaeger Tracing: https://jaeger.company.com/

### „Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥
- Slack: #incident-response
- Zoom: https://zoom.us/j/incident-room
- Status Page: https://status.company.com/
EOF
}

# ÈÅãÁî®Ëá™ÂãïÂåñÁîüÊàê
generate_automation() {
    log_info "ÈÅãÁî®Ëá™ÂãïÂåñ„Çπ„ÇØ„É™„Éó„Éà„ÇíÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô..."
    
    load_project_info
    
    # „Éá„Éó„É≠„Ç§Ëá™ÂãïÂåñ
    generate_deployment_automation
    
    # „Çπ„Ç±„Éº„É™„É≥„Ç∞Ëá™ÂãïÂåñ
    generate_scaling_automation
    
    # ÂÆöÊúü„É°„É≥„ÉÜ„Éä„É≥„ÇπËá™ÂãïÂåñ
    generate_maintenance_automation
    
    # ÈöúÂÆ≥Âæ©ÊóßËá™ÂãïÂåñ
    generate_recovery_automation
    
    log_success "ÈÅãÁî®Ëá™ÂãïÂåñÁîüÊàêÂÆå‰∫Ü"
}

# „Çπ„Ç±„Éº„É™„É≥„Ç∞Ëá™ÂãïÂåñ
generate_scaling_automation() {
    cat > "$OUTPUT_DIR/automation/scripts/auto-scaling.sh" << 'EOF'
#!/bin/bash
# Auto Scaling Ëá™ÂãïÂåñ„Çπ„ÇØ„É™„Éó„Éà

set -euo pipefail

# Ë®≠ÂÆö
ASG_NAME="web-app-asg"
MIN_SIZE=2
MAX_SIZE=20
TARGET_CPU=70
SCALE_UP_COOLDOWN=300
SCALE_DOWN_COOLDOWN=300

# „É≠„Ç∞Èñ¢Êï∞
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# „É°„Éà„É™„ÇØ„ÇπÂèñÂæó
get_cpu_utilization() {
    aws cloudwatch get-metric-statistics \
        --namespace AWS/EC2 \
        --metric-name CPUUtilization \
        --dimensions Name=AutoScalingGroupName,Value=$ASG_NAME \
        --start-time $(date -u -d '10 minutes ago' +%Y-%m-%dT%H:%M:%S) \
        --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
        --period 300 \
        --statistics Average \
        --query 'Datapoints[0].Average' \
        --output text
}

# ÁèæÂú®„ÅÆ„Ç≠„É£„Éë„Ç∑„ÉÜ„Ç£ÂèñÂæó
get_current_capacity() {
    aws autoscaling describe-auto-scaling-groups \
        --auto-scaling-group-names $ASG_NAME \
        --query 'AutoScalingGroups[0].DesiredCapacity' \
        --output text
}

# „Çπ„Ç±„Éº„É´„Ç¢„ÉÉ„Éó
scale_up() {
    local current_capacity=$1
    local new_capacity=$((current_capacity + 2))
    
    if [ $new_capacity -gt $MAX_SIZE ]; then
        new_capacity=$MAX_SIZE
    fi
    
    log "Scaling up from $current_capacity to $new_capacity"
    
    aws autoscaling set-desired-capacity \
        --auto-scaling-group-name $ASG_NAME \
        --desired-capacity $new_capacity \
        --honor-cooldown
}

# „Çπ„Ç±„Éº„É´„ÉÄ„Ç¶„É≥
scale_down() {
    local current_capacity=$1
    local new_capacity=$((current_capacity - 1))
    
    if [ $new_capacity -lt $MIN_SIZE ]; then
        new_capacity=$MIN_SIZE
    fi
    
    log "Scaling down from $current_capacity to $new_capacity"
    
    aws autoscaling set-desired-capacity \
        --auto-scaling-group-name $ASG_NAME \
        --desired-capacity $new_capacity \
        --honor-cooldown
}

# „É°„Ç§„É≥Âá¶ÁêÜ
main() {
    log "Starting auto-scaling check"
    
    local cpu_util=$(get_cpu_utilization)
    local current_capacity=$(get_current_capacity)
    
    log "Current CPU utilization: ${cpu_util}%"
    log "Current capacity: $current_capacity"
    
    if (( $(echo "$cpu_util > 80" | bc -l) )); then
        log "High CPU detected, scaling up"
        scale_up $current_capacity
    elif (( $(echo "$cpu_util < 40" | bc -l) )); then
        log "Low CPU detected, scaling down"
        scale_down $current_capacity
    else
        log "CPU within normal range, no action needed"
    fi
    
    log "Auto-scaling check completed"
}

main "$@"
EOF
}

# ÂÖ®ÈÅãÁî®Ë®≠ÂÆöÁîüÊàê
generate_all() {
    log_info "ÂÖ®„Å¶„ÅÆÈÅãÁî®Ë®≠ÂÆö„ÇíÁîüÊàê„Åó„Å¶„ÅÑ„Åæ„Åô..."
    
    load_project_info
    
    # ÂêÑÁ®ÆË®≠ÂÆö„ÇíÁîüÊàê
    generate_monitoring "$MONITORING_LEVEL"
    generate_alerting "$SLO"
    generate_logging
    generate_backup
    generate_runbooks
    generate_automation
    
    # „Éû„Çπ„Çø„Éº„Éâ„Ç≠„É•„É°„É≥„ÉàÁîüÊàê
    generate_ops_master_doc
    
    log_success "ÂÖ®ÈÅãÁî®Ë®≠ÂÆöÁîüÊàêÂÆå‰∫Ü"
}

# ÈÅãÁî®„Éû„Çπ„Çø„Éº„Éâ„Ç≠„É•„É°„É≥„ÉàÁîüÊàê
generate_ops_master_doc() {
    cat > "$OUTPUT_DIR/operations-guide.md" << EOF
# ÈÅãÁî®„Ç¨„Ç§„Éâ

## Ê¶ÇË¶Å
- **„Éó„É≠„Ç∏„Çß„ÇØ„Éà**: $(basename "$(pwd)")
- **SLO**: $SLO
- **Áõ£Ë¶ñ„É¨„Éô„É´**: $MONITORING_LEVEL
- **„Éá„Éó„É≠„Ç§Á®ÆÂà•**: $DEPLOYMENT_TYPE

## ÁîüÊàê„Åï„Çå„ÅüË®≠ÂÆö

### Áõ£Ë¶ñ„Éª„Ç¢„É©„Éº„Éà
- [x] CloudWatch Ë®≠ÂÆö
- [x] „Ç¢„É©„Éº„Éà„É´„Éº„É´
- [x] „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâË®≠ÂÆö
- [x] PagerDuty Áµ±Âêà

### „É≠„Ç∞ÁÆ°ÁêÜ
- [x] „É≠„Ç∞ÂèéÈõÜË®≠ÂÆö
- [x] „É≠„Ç∞„Éë„Éº„ÇπË®≠ÂÆö
- [x] ‰øùÊåÅ„Éù„É™„Ç∑„Éº
- [x] „Ç¢„Éº„Ç´„Ç§„ÉñË®≠ÂÆö

### „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÉªDR
- [x] „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóË®àÁîª
- [x] Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Çπ„ÇØ„É™„Éó„Éà
- [x] Âæ©ÂÖÉÊâãÈ†Ü
- [x] ÁÅΩÂÆ≥Âæ©ÊóßË®àÁîª

### ÈÅãÁî®Ëá™ÂãïÂåñ
- [x] „Éá„Éó„É≠„Ç§Ëá™ÂãïÂåñ
- [x] „Çπ„Ç±„Éº„É™„É≥„Ç∞Ëá™ÂãïÂåñ
- [x] ÂÆöÊúü„É°„É≥„ÉÜ„Éä„É≥„Çπ
- [x] ÈöúÂÆ≥Âæ©ÊóßËá™ÂãïÂåñ

### „É©„É≥„Éñ„ÉÉ„ÇØ
- [x] „Ç§„É≥„Ç∑„Éá„É≥„ÉàÂØæÂøú
- [x] „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞
- [x] ÂÆöÊúü„É°„É≥„ÉÜ„Éä„É≥„ÇπÊâãÈ†Ü

## ÈÅãÁî®„Éó„É≠„Çª„Çπ

### Êó•Ê¨°„Çø„Çπ„ÇØ
- [ ] „Ç∑„Çπ„ÉÜ„É†Áä∂ÊÖãÁ¢∫Ë™ç
- [ ] „Ç¢„É©„Éº„ÉàÁ¢∫Ë™ç„ÉªÂØæÂøú
- [ ] „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÁä∂ÊÖãÁ¢∫Ë™ç
- [ ] „Ç≥„Çπ„ÉàÁ¢∫Ë™ç

### ÈÄ±Ê¨°„Çø„Çπ„ÇØ
- [ ] „Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„É¨„Éì„É•„Éº
- [ ] „Çª„Ç≠„É•„É™„ÉÜ„Ç£„Éë„ÉÉ„ÉÅÈÅ©Áî®
- [ ] „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÉÜ„Çπ„Éà
- [ ] „Ç≠„É£„Éë„Ç∑„ÉÜ„Ç£„Éó„É©„É≥„Éã„É≥„Ç∞

### ÊúàÊ¨°„Çø„Çπ„ÇØ
- [ ] SLO„É¨„Éì„É•„Éº
- [ ] „Ç§„É≥„Ç∑„Éá„É≥„Éà„É¨„Éì„É•„Éº
- [ ] „Ç≥„Çπ„ÉàÊúÄÈÅ©Âåñ
- [ ] ÁÅΩÂÆ≥Âæ©Êóß„ÉÜ„Çπ„Éà

## SLO/SLI Ë®≠ÂÆö

### ÂèØÁî®ÊÄß SLO: $SLO
- **Ê∏¨ÂÆöÊúüÈñì**: 30Êó•Èñì
- **„Ç®„É©„Éº„Éê„Ç∏„Çß„ÉÉ„Éà**: $(calculate_error_budget "$SLO")
- **„Ç¢„É©„Éº„ÉàÈñæÂÄ§**: „Ç®„É©„Éº„Éê„Ç∏„Çß„ÉÉ„Éà„ÅÆ50%Ê∂àË≤ªÊôÇ

### „É¨„Çπ„Éù„É≥„Çπ„Çø„Ç§„É† SLO: ${RESPONSE_TIME}Áßí
- **Ê∏¨ÂÆöÂØæË±°**: 95„Éë„Éº„Çª„É≥„Çø„Ç§„É´
- **Ê∏¨ÂÆöÊúüÈñì**: 30Êó•Èñì
- **„Ç¢„É©„Éº„ÉàÈñæÂÄ§**: SLOÈÅïÂèçÁéá > 5%

## Á∑äÊÄ•ÈÄ£Áµ°ÂÖà

### „Ç™„É≥„Ç≥„Éº„É´‰ΩìÂà∂
- **Âπ≥Êó• (9:00-18:00)**: „ÉÅ„Éº„É†ÂÖ®Âì°
- **Âπ≥Êó•Â§úÈñì„Éª‰ºëÊó•**: „Ç™„É≥„Ç≥„Éº„É´ÊãÖÂΩìËÄÖ
- **„Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥**: „Éû„Éç„Éº„Ç∏„É£„Éº ‚Üí CTO

### Â§ñÈÉ®„Éô„É≥„ÉÄ„Éº
- **AWS „Çµ„Éù„Éº„Éà**: [„Çµ„Éù„Éº„Éà„Ç±„Éº„Çπ](https://console.aws.amazon.com/support/)
- **PagerDuty**: support@pagerduty.com
- **Á¨¨‰∏âËÄÖÁõ£Ë¶ñ**: ÂêÑ„Éô„É≥„ÉÄ„Éº„Çµ„Éù„Éº„Éà

## „ÉÑ„Éº„É´„Éª„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ

### Áõ£Ë¶ñ
- [CloudWatch Dashboard](https://console.aws.amazon.com/cloudwatch/)
- [Custom Dashboard](http://monitoring.company.com/)

### „É≠„Ç∞
- [CloudWatch Logs](https://console.aws.amazon.com/cloudwatch/logs)
- [Log Analysis](http://logs.company.com/)

### „Ç¢„É©„Éº„Éà
- [PagerDuty](https://company.pagerduty.com/)
- [Slack #alerts](https://company.slack.com/channels/alerts)

## ÊîπÂñÑË®àÁîª

### Áü≠Êúü (1-3„É∂Êúà)
- [ ] Áõ£Ë¶ñ„É°„Éà„É™„ÇØ„ÇπÁ≤æÂ∫¶Âêë‰∏ä
- [ ] „Ç¢„É©„Éº„ÉàÁ≤æÂ∫¶Âêë‰∏äÔºà„Éé„Ç§„Ç∫ÂâäÊ∏õÔºâ
- [ ] Ëá™ÂãïÂæ©Êóß„Çπ„ÇØ„É™„Éó„ÉàËøΩÂä†

### ‰∏≠Êúü (3-6„É∂Êúà)
- [ ] „Ç´„Ç™„Çπ„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞Â∞éÂÖ•
- [ ] ‰∫àÊ∏¨ÁöÑ„Çπ„Ç±„Éº„É™„É≥„Ç∞ÂÆüË£Ö
- [ ] È´òÂ∫¶„Å™„É≠„Ç∞ÂàÜÊûê

### Èï∑Êúü (6-12„É∂Êúà)
- [ ] AI/ML „Å´„Çà„ÇãÁï∞Â∏∏Ê§úÁü•
- [ ] ÂÆåÂÖ®„Å™Ëá™Â∑±‰øÆÂæ©„Ç∑„Çπ„ÉÜ„É†
- [ ] „Éû„É´„ÉÅ„É™„Éº„Ç∏„Éß„É≥ÂØæÂøú
EOF
}

# „Ç®„É©„Éº„Éê„Ç∏„Çß„ÉÉ„ÉàË®àÁÆó
calculate_error_budget() {
    local slo="$1"
    case "$slo" in
        "99.0%") echo "1.0%" ;;
        "99.9%") echo "0.1%" ;;
        "99.95%") echo "0.05%" ;;
        "99.99%") echo "0.01%" ;;
        *) echo "0.1%" ;;
    esac
}

# „É°„Ç§„É≥Âá¶ÁêÜ
main() {
    echo "üîß $AGENT_NAME v$AGENT_VERSION"
    echo "============================="
    
    # ÂàùÊúüÂåñ
    init_sre
    
    # ÂºïÊï∞„ÅÆÂá¶ÁêÜ
    case "$1" in
        --monitoring)
            shift
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    --level)
                        generate_monitoring "$2"
                        shift 2
                        ;;
                    *)
                        generate_monitoring
                        shift
                        ;;
                esac
            done
            ;;
        --alerting)
            shift
            while [[ $# -gt 0 ]]; do
                case "$1" in
                    --slo)
                        generate_alerting "$2"
                        shift 2
                        ;;
                    *)
                        generate_alerting
                        shift
                        ;;
                esac
            done
            ;;
        --logging)
            generate_logging
            ;;
        --backup)
            generate_backup
            ;;
        --runbooks)
            generate_runbooks
            ;;
        --automation)
            generate_automation
            ;;
        --all)
            generate_all
            ;;
        --help|"")
            show_usage
            ;;
        *)
            log_error "‰∏çÊòé„Å™„Ç™„Éó„Ç∑„Éß„É≥: $1"
            show_usage
            exit 1
            ;;
    esac
}

# ÂÆüË°å
main "$@"